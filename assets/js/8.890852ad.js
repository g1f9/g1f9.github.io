(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{280:function(t,s,n){"use strict";n.r(s);var a=n(38),e=Object(a.a)({},function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"babel"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#babel","aria-hidden":"true"}},[t._v("#")]),t._v(" Babel")]),t._v(" "),n("h2",{attrs:{id:"概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#概述","aria-hidden":"true"}},[t._v("#")]),t._v(" 概述")]),t._v(" "),n("blockquote",[n("p",[t._v("以下内容均基于 babel7。在 babel7中，插件名以 @babel 开头")])]),t._v(" "),n("p",[t._v("Babel 是一个 JavaScript 编译器，工具链，主要用于将 ES6 版本的代码转换为向后兼容的 JavaScript 语法，以便能够运行在当前和旧版本的浏览器或其他环境中。babel 主要能做以下事情")]),t._v(" "),n("ol",[n("li",[t._v("语法转换")]),t._v(" "),n("li",[t._v("polyfill。在目标环境中添加缺失的特性")]),t._v(" "),n("li",[t._v("源码转换")]),t._v(" "),n("li",[t._v("more")])]),t._v(" "),n("p",[t._v("babel 核心不处理任何代码转换，它只负责将代码转换成 ast，然后将 ast 交给插件去处理。在不使用任何插件的情况下就相当于"),n("code",[t._v("(code)=>code")]),t._v("。插件负责语法转换，并且一个插件只负责一类代码转换。例如 @babel/plugin-transform-arrow-functions 负责将箭头函数转换为普通函数，如果你加入了这个插件，编译过后的箭头函数就能输出为普通函数，如果不加入，那么箭头函数将会原样输出。默认不加任何插件的情况下，输出的代码就等于输入的代码。")]),t._v(" "),n("div",{staticClass:"language-javascript extra-class"},[n("pre",{pre:!0,attrs:{class:"language-javascript"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("f")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//./node_modules/.bin/babel src --out-dir lib --plugins=@babel/plugin-transform-arrow-functions")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//使用 @babel/plugin-transform-arrow-functions 转换后")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("f")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 可以看到箭头函数转了，但是 const 没转")]),t._v("\n")])])]),n("p",[t._v("在上面的例子，使用箭头函数插件，但是他并没有转换 "),n("code",[t._v("const")]),t._v("，那么为了转换 const 我们就需要引入另外一个插件。因此为了完整地将 es6 转换成对应 es5 代码需要往配置中加入大量的插件，为了避免这样重复的工作。引入了 preset，即一组预设的插件，由预设来管理我们目标的插件集合。@babel/preset-env 可以根据我们配置的目标环境提供一组对应插件。")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("npm install "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v("save"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("dev @babel"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("preset"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("env\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("node_modules"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bin"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("babel src "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("dir lib "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v("presets"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("@babel"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("preset"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("env\n")])])]),n("p",[t._v("上述预设默认情况下支持所有最新的 JavaScript 特性。")]),t._v(" "),n("p",[t._v("@babel/preset-env 也支持 polyfill，可以根据使用情况和目标环境自动引入对应的文件，传入 useBuiltIns，和对应的 corejs 参数即可。@babel-core+@babel/preset-env 已经能很好工作了，但是在编译过后的文件中，存在大量重复定义的帮助方法，会影响最后的整体体积。为了进一步优化，引入 @babel/plugin-transform-runtime 这个插件。默认情况下这个插件可以把这些内联的帮助函数定义改成从 runtime/helpers 中引入。当然这个插件也不只这个功能。")]),t._v(" "),n("h3",{attrs:{id:"简单案例"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#简单案例","aria-hidden":"true"}},[t._v("#")]),t._v(" 简单案例")]),t._v(" "),n("p",[n("code",[t._v("yarn add @babel/cli @babel/core @babel/preset-env @babel/plugin-transform-runtime -D")])]),t._v(" "),n("p",[n("code",[t._v("yarn add core-js@3")])]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 项目根目录")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//.babelrc")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"presets"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@babel/preset-env"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"useBuiltIns"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"usage"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"corejs"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"plugins"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@babel/plugin-transform-runtime"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//package.json")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"scripts"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"compile"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"babel src --out-dir dist"')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[n("code",[t._v("npm run compile")])]),t._v(" "),n("h2",{attrs:{id:"babel-preset-env"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#babel-preset-env","aria-hidden":"true"}},[t._v("#")]),t._v(" @babel/preset-env")]),t._v(" "),n("p",[t._v("@babel/preset-env 是一个十分灵活的预设，它使我们能够使用最新 JS 语法特性，又避免需要我们去手动配置那些细微的语法转换，也支持根据对应的环境进行 polyfill（需要配置）。@babel/preset-env 的开源得益于众多的优秀的开源项目，例如 "),n("a",{attrs:{href:"https://github.com/browserslist/browserslist",target:"_blank",rel:"noopener noreferrer"}},[t._v("browserslist"),n("OutboundLink")],1),t._v("，"),n("a",{attrs:{href:"https://github.com/kangax/compat-table",target:"_blank",rel:"noopener noreferrer"}},[t._v("compat-table"),n("OutboundLink")],1),t._v(" 和 "),n("a",{attrs:{href:"https://github.com/Kilian/electron-to-chromium",target:"_blank",rel:"noopener noreferrer"}},[t._v("electron-to-chromium"),n("OutboundLink")],1),t._v("，从这些开源项目获取数据，来获取对应目标环境的 JavaScript 语法特性，从而更好的进行语法转换和 polyfill。")]),t._v(" "),n("h3",{attrs:{id:"browserlist-集成"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#browserlist-集成","aria-hidden":"true"}},[t._v("#")]),t._v(" browserlist 集成")]),t._v(" "),n("p",[t._v("对于浏览器或者基于 Electron 的项目，推荐使用一个 .browserlistrc 文件来指定目标环境，许多工具也使用了这个文件，例如 autoprefixer，stylelint，eslint-plugin-compact 等。若果没有配置 target 或者 ignoreBrowserlistConfig，那么 preset-env 就默认使用 browserlist 的源配置。")]),t._v(" "),n("h4",{attrs:{id:"案例"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例","aria-hidden":"true"}},[t._v("#")]),t._v(" 案例")]),t._v(" "),n("h5",{attrs:{id:"browserslist"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#browserslist","aria-hidden":"true"}},[t._v("#")]),t._v(" browserslist")]),t._v(" "),n("p",[t._v("浏览器市场份额大于 0.25%，（忽略没有安全更新的浏览器，例如 ie10 和黑莓）。具体的配置方式可以参考 "),n("a",{attrs:{href:"https://github.com/browserslist/browserslist#queries",target:"_blank",rel:"noopener noreferrer"}},[t._v("browserslit"),n("OutboundLink")],1),t._v(" 的文档")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("> 0.25%\nnot dead\n")])])]),n("h3",{attrs:{id:"options-配置"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#options-配置","aria-hidden":"true"}},[t._v("#")]),t._v(" Options 配置")]),t._v(" "),n("p",[n("strong",[n("code",[t._v("targets")])])]),t._v(" "),n("p",[n("code",[t._v("string|Array<string>|{[string]:string}")]),t._v(",默认 "),n("code",[t._v("{}")])]),t._v(" "),n("p",[t._v("描述项目支持的浏览器环境")]),t._v(" "),n("p",[t._v("可以是兼容 browserslist 的查询")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"targets"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('">0.25%,not dead"')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("也可以指定某种浏览器的最小版本支持")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"targets"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"chrome"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"58"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"ie"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"11"')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("如果没有指定没有对应的 target，@babel/preset-env 默认将会转换"),n("strong",[t._v("所有")]),t._v("的 "),n("strong",[t._v("ECMAScript2015+")]),t._v(" 的代码。")]),t._v(" "),n("blockquote",[n("p",[t._v("不推荐这样使用 preset-env，这样无法发挥出它指定浏览器转换的优势。特别是开启 polyfill 属性时，一定要指定这个 target 属性，否则引入的 polyfill 将会非常多")])]),t._v(" "),n("p",[t._v("其他 targets 的配置")]),t._v(" "),n("ol",[n("li",[n("code",[t._v("targets.esmodules")]),t._v("。 用来指定目标环境是否支持 es6 的模块机制，开启的话 browsers将会被忽略")]),t._v(" "),n("li",[n("code",[t._v("targets.node")]),t._v("。编译成 node 版本，可以选值"),n("code",[t._v('string|"current"|true')])]),t._v(" "),n("li",[n("code",[t._v("targets.safari")]),t._v("。编译成 safari 的预览版本。")]),t._v(" "),n("li",[n("code",[t._v("targets.browsers")]),t._v("。"),n("code",[t._v("string|Array<string>")]),t._v("，使用 browerserslist 的查询语句，例如 "),n("code",[t._v("last 2 versions,>5%,safari tp")]),t._v("。")])]),t._v(" "),n("p",[n("strong",[n("code",[t._v("debug")])])]),t._v(" "),n("p",[n("code",[t._v("boolean")]),t._v("，默认 "),n("code",[t._v("false")])]),t._v(" "),n("p",[t._v("输出使用的 targets/plugins 和 插件支持版本信息到控制台")]),t._v(" "),n("p",[n("strong",[n("code",[t._v("useBuiltIns")])])]),t._v(" "),n("ol",[n("li",[t._v("useBuiltIns:'usage'。不需要在 webpack.config.js 的任何入口或者代码引入 polyfill。将会自动分析用到的 API，然后在对应的文件自动引入。相当于自动的 require 或者 import")]),t._v(" "),n("li",[t._v("useBuiltIns:'entry'。需要在源码的最顶部通过 import 或者 require 引入，类似上面的直接引入。多次引入会报错")]),t._v(" "),n("li",[t._v("useBuiltIns:false。在 webpack.config.js 中，通过入口引入。如 module.exports = {entry:['@babel/polyfill','./app/js']}")])]),t._v(" "),n("p",[n("strong",[n("code",[t._v("forceAllTransforms")])])]),t._v(" "),n("p",[n("code",[t._v("boolean")]),t._v("，默认 "),n("code",[t._v("false")])]),t._v(" "),n("p",[t._v("默认情况下，这个预设将会运行目标环境所需要的所有转换。当输出需要通过 UglifyJs 或者一个完全只支持 ES5 的环境，这个选项将会很有用")]),t._v(" "),n("p",[n("strong",[n("code",[t._v("configPath")])])]),t._v(" "),n("p",[n("code",[t._v("string")]),t._v("，默认 "),n("code",[t._v("precess.cwd")])]),t._v(" "),n("p",[t._v("指定搜索 browserslist 的起始目录，会不停向上搜索直到根目录")]),t._v(" "),n("p",[n("strong",[n("code",[t._v("shippedProposal")])])]),t._v(" "),n("p",[n("code",[t._v("boolean")]),t._v("，默认 "),n("code",[t._v("false")])]),t._v(" "),n("p",[t._v("启动对于浏览器中内置特性的支持，例如目标浏览器支持一些比较新的语言特性，并且有着更好的表现，可以通过开启这个选项来避免进行代码进行转换。")]),t._v(" "),n("p",[n("strong",[n("code",[t._v("ignoreBrowserslistConfig")])])]),t._v(" "),n("p",[n("code",[t._v("boolean")]),t._v("，默认 "),n("code",[t._v("false")])]),t._v(" "),n("p",[t._v("是否忽略 browserslist 的配置。开启时不会检索 browserslist，")]),t._v(" "),n("p",[t._v("另外还有 "),n("code",[t._v("spec")]),t._v("，"),n("code",[t._v("loose")]),t._v("，"),n("code",[t._v("include")]),t._v("，"),n("code",[t._v("exclude")]),t._v("。"),n("code",[t._v("include/exclude")]),t._v(" 用来添加/移除某些插件。"),n("code",[t._v("loose")]),t._v(" 编译时启用宽松模式，"),n("code",[t._v("spec")]),t._v(" 启用更符合规范的编译。")]),t._v(" "),n("h2",{attrs:{id:"babel-plugin-transform-runtime"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#babel-plugin-transform-runtime","aria-hidden":"true"}},[t._v("#")]),t._v(" @babel/plugin-transform-runtime")]),t._v(" "),n("p",[t._v("这个插件做以下几件事情")]),t._v(" "),n("ol",[n("li",[t._v("若使用了 generators/async，自动引入 @babel/runtime/regenerator")]),t._v(" "),n("li",[t._v("使用 corejs 这个选项时，自动从 corejs 引入相关帮助 API。例如使用了 Promise，那么就从 corejs 中引入 Promise 这个类，从而起到了 polyfill 的作用。本意是为了提供给 JS 包使用，使它们可以更自由的使用浏览器的内建 API，避免假设用户已经做了 polyfill 的情况。这个选项需要配和相关的 @babel/runtime-corejs包使用")]),t._v(" "),n("li",[t._v("移除 babel 编译过程中内联的帮助函数，改成从 @babel/runtime/helps 从引入。从而减少生成的包的体积")])]),t._v(" "),n("h3",{attrs:{id:"配置"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#配置","aria-hidden":"true"}},[t._v("#")]),t._v(" 配置")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 默认配置")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"plugins"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@babel/plugin-transform-runtime"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"absouluteRuntime"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"corejs"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//对应点 2")]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"helpers"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 对应点 3")]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"regenerator"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//对应点 1")]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"useESModules"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//是否开启 es6 模块，开启时 helpers 模块将以 es6 的形式导出，而不经过 @babel/plugin-transform-modules-commonjs")]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"corejs"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#corejs","aria-hidden":"true"}},[t._v("#")]),t._v(" corejs")]),t._v(" "),n("p",[n("code",[t._v("boolean|number")]),t._v("，默认 "),n("code",[t._v("false")])]),t._v(" "),n("p",[t._v("指定 polyfill 的 corejs 版本。并且需要安装对应的 runtime-corejs 版本。如指定 corejs:3，那么就需要安装 @babel/runtime-corejs3。")]),t._v(" "),n("p",[t._v('plugin-transform-runtime 的引入是不污染的全局的作用域，这是它 polyfill 的一个区别，并且它和 polyfill 理念是不一样的。polyfill 的想法是垫平环境的差异，因此需要根据环境差异来执行垫的操作，比如项目运行目标是运行在最新 chrome 上，那么它可能并不需要这个垫的操作。而 plugin-transform-runtime 是想提供一个可以自由使用内建 API 的环境给我们，使我们能毫无顾虑地使用这些内建 API，相当于一种全量引入。比如 Promise，那么就会自动从 core-js 中引入 Promise，相当于帮我们自动写了一条 require 语句。而且它并不会考虑目标环境，不管我们的目标环境是什么都会处理引入。在 corejs:2 选项中它能自动引入的帮助方法有限，可能无法识别引入 "foobar".includes("foo") 这类实例方法，在使用 orejs:3 中好像没有这个问题。')]),t._v(" "),n("p",[t._v('由于 plugin-transform-runtime 是按需提供一个 js 环境的，更适用于库和工具。而对于应用而言，它的目标环境明确，使用 useBuiltIns:"usage" 来处理更合适，能有效减少打包后的体积。')]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" promise "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Promise")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 转成")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"use strict"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" _promise "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@babel/runtime-corejs2/core-js/promise"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//！注意此处 Promise 直接从 runtime-corejs2 中引入，而不是直接依赖于全局对象。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" _promise2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_interopRequireDefault")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_promise"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" promise "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("_promise2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这意味着我们可以无缝使用这些内建的原生方法和静态方法")]),t._v("\n")])])]),n("h4",{attrs:{id:"helpers"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#helpers","aria-hidden":"true"}},[t._v("#")]),t._v(" helpers")]),t._v(" "),n("p",[n("code",[t._v("boolean")]),t._v("，默认 "),n("code",[t._v("true")])]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 源码")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Person")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//未开启 helpers")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"use strict"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//！这是重复定义项")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_classCallCheck")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Constructor")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("instanceof")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Constructor")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeError")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Cannot call a class as a function"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("Person")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Person")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_classCallCheck")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 开启 helpers")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"use strict"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//！classCallCheck 从 runtime/helpers 引入，减少了打包大小")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" _classCallCheck2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@babel/runtime/helpers/classCallCheck"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" _classCallCheck3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_interopRequireDefault")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_classCallCheck2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_interopRequireDefault")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("obj")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" obj "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" obj"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__esModule "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" obj "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" obj "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("Person")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Person")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _classCallCheck3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("default"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("h2",{attrs:{id:"babel-cli"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#babel-cli","aria-hidden":"true"}},[t._v("#")]),t._v(" @babel/cli")]),t._v(" "),n("p",[t._v("@babel/cli 自带了一个内置的 CLI 命令行工具，可以通过命令行来编译文件。此外各种能直接调用的脚本都存放在 @babel/cli/bin 中。主要有 babel-external-helpers.js 和 Babel cli 都主脚本 babel.js")]),t._v(" "),n("h3",{attrs:{id:"用法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#用法","aria-hidden":"true"}},[t._v("#")]),t._v(" 用法")]),t._v(" "),n("p",[n("code",[t._v("babel main.js")]),t._v(" 即编译 main.js 文件，"),n("strong",[t._v("支持目录")])]),t._v(" "),n("p",[n("code",[t._v("babel main.js -o lib.js")]),t._v(" -o 或者 --out-file 输出到某个文件")]),t._v(" "),n("p",[n("code",[t._v("babel main.js --watch -o lib.js")]),t._v(" -w 或者 --watch 监听文件修改，重新编译")]),t._v(" "),n("p",[n("code",[t._v("bable main.js -o lib.js --source-maps")]),t._v(" --source-maps 用来输出 source-map")]),t._v(" "),n("p",[n("code",[t._v("babel src --out-dir lib")]),t._v(" -d 或者 --out-dir 输出到某个目录")]),t._v(" "),n("h2",{attrs:{id:"the-super-tiny-compiler"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#the-super-tiny-compiler","aria-hidden":"true"}},[t._v("#")]),t._v(" the super tiny compiler")]),t._v(" "),n("p",[n("a",{attrs:{href:"https://github.com/jamiebuilds/the-super-tiny-compiler/blob/master/the-super-tiny-compiler.js",target:"_blank",rel:"noopener noreferrer"}},[t._v("the super tiny compiler"),n("OutboundLink")],1),t._v(" 是一个小型的编译器，通过简化一些流程从而让我们更高效理解 Babel 是怎么工作的。整篇代码移除注释只不过 200 多行，非常适合于学习。")]),t._v(" "),n("p",[t._v("大部分的编译程序工作流程分为以下三个步骤")]),t._v(" "),n("ol",[n("li",[n("strong",[t._v("Parsing")]),t._v("。把源码解析更加抽象的产物，例如中间代码或抽象语法输")]),t._v(" "),n("li",[n("strong",[t._v("Transformation")]),t._v("。对于抽象产物进行操作")]),t._v(" "),n("li",[n("strong",[t._v("Code Generation")]),t._v(".即最终代码生成")])]),t._v(" "),n("h3",{attrs:{id:"parsing"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#parsing","aria-hidden":"true"}},[t._v("#")]),t._v(" Parsing")]),t._v(" "),n("p",[t._v("解析的过程分为两个步骤，词法分析和语法分析。")]),t._v(" "),n("p",[t._v("词法分析的过程即对于源码进行切割，形成一个个 token。即 token 化。token 是一个对象数组，描述了一小段独立的语法片段，对象内描述可以是数字，标签，标点符号，操作符或者任意东西。")]),t._v(" "),n("p",[t._v("语法分析的过程将 token 重新组成一个描述各个语法部分之间关系的对象。例如中间代码或者抽象语法树。抽象语法树即 ast，是一个包含着丰富信息，容易操作的，深层嵌套的对象。")]),t._v(" "),n("p",[t._v("列如对于下列语法")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("\n(add 2 (subtract 4 2))\n\n// token 化之后\n\n[\n     { type: 'paren',  value: '('        },\n     { type: 'name',   value: 'add'      },\n     { type: 'number', value: '2'        },\n     { type: 'paren',  value: '('        },\n     { type: 'name',   value: 'subtract' },\n     { type: 'number', value: '4'        },\n     { type: 'number', value: '2'        },\n     { type: 'paren',  value: ')'        },\n     { type: 'paren',  value: ')'        },\n   ]\n\n形成抽象语法树后\n\n   {\n     type: 'Program',\n     body: [{\n       type: 'CallExpression',\n       name: 'add',\n       params: [{\n         type: 'NumberLiteral',\n         value: '2',\n       }, {\n         type: 'CallExpression',\n         name: 'subtract',\n         params: [{\n           type: 'NumberLiteral',\n           value: '4',\n         }, {\n           type: 'NumberLiteral',\n           value: '2',\n         }]\n       }]\n     }]\n   }\n")])])]),n("h3",{attrs:{id:"示例代码"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示例代码","aria-hidden":"true"}},[t._v("#")]),t._v(" 示例代码")]),t._v(" "),n("p",[n("strong",[t._v("!TODO，\b加上自己的理解")])]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("tokenizer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// A `current` variable for tracking our position in the code like a cursor.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" current "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And a `tokens` array for pushing our tokens to.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" tokens "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We start by creating a `while` loop where we are setting up our `current`")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// variable to be incremented as much as we want `inside` the loop.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We do this because we may want to increment `current` many times within a")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// single loop because our tokens can be any length.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We're also going to store the `current` character in the `input`.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The first thing we want to check for is an open parenthesis. This will")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// later be used for `CallExpression` but for now we only care about the")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// character.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We check to see if we have an open parenthesis:")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'('")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If we do, we push a new token with the type `paren` and set the value")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// to an open parenthesis.")]),t._v("\n      tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'paren'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'('")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Then we increment `current`")]),t._v("\n      current"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And we `continue` onto the next cycle of the loop.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next we're going to check for a closing parenthesis. We do the same exact")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// thing as before: Check for a closing parenthesis, add a new token,")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// increment `current`, and `continue`.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("')'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'paren'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("')'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      current"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Moving on, we're now going to check for whitespace. This is interesting")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// because we care that whitespace exists to separate characters, but it")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// isn't actually important for us to store as a token. We would only throw")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// it out later.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// So here we're just going to test for existence and if it does exist we're")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// going to just `continue` on.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("WHITESPACE")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/\\s/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("WHITESPACE")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("test")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      current"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The next type of token is a number. This is different than what we have")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// seen before because a number could be any number of characters and we")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// want to capture the entire sequence of characters as one token.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   (add 123 456)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//        ^^^ ^^^")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//        Only two separate tokens")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// So we start this off when we encounter the first number in a sequence.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("NUMBERS")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[0-9]/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("NUMBERS")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("test")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We're going to create a `value` string that we are going to push")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// characters to.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Then we're going to loop through each character in the sequence until")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// we encounter a character that is not a number, pushing each character")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// that is a number to our `value` and incrementing `current` as we go.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("NUMBERS")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("test")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// After that we push our `number` token to the `tokens` array.")]),t._v("\n      tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And we continue on.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll also add support for strings in our language which will be any")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// text surrounded by double quotes (").')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//   (concat "foo" "bar")')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//            ^^^   ^^^ string tokens")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll start by checking for the opening quote:")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\"'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Keep a `value` variable for building up our string token.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll skip the opening double quote in our token.")]),t._v("\n      char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Then we'll iterate through each character until we reach another")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// double quote.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\"'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Skip the closing double quote.")]),t._v("\n      char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And add our `string` token to the `tokens` array.")]),t._v("\n      tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'string'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The last type of token will be a `name` token. This is a sequence of")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// letters instead of numbers, that are the names of functions in our lisp")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// syntax.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   (add 2 4)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//    ^^^")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//    Name token")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("LETTERS")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[a-z]/i")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("LETTERS")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("test")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Again we're just going to loop through all the letters pushing them to")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// a value.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("LETTERS")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("test")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        char "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And pushing that value as a token with the type `name` and continuing.")]),t._v("\n      tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Finally if we have not matched a character by now, we're going to throw")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// an error and completely exit.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeError")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'I dont know what this character is: '")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" char"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Then at the end of our `tokenizer` we simply return the tokens array.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * ============================================================================\n *                                 ヽ/❀o ل͜ o\\ﾉ\n *                                THE PARSER!!!\n * ============================================================================\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * For our parser we're going to take our array of tokens and turn it into an\n * AST.\n *\n *   [{ type: 'paren', value: '(' }, ...]   =>   { type: 'Program', body: [...] }\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Okay, so we define a `parser` function that accepts our array of `tokens`.")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("parser")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("tokens")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Again we keep a `current` variable that we will use as a cursor.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" current "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// But this time we're going to use recursion instead of a `while` loop. So we")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// define a `walk` function.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("walk")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Inside the walk function we start by grabbing the `current` token.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" token "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We're going to split each type of token off into a different code path,")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// starting off with `number` tokens.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We test to see if we have a `number` token.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If we have one, we'll increment `current`.")]),t._v("\n      current"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And we'll return a new AST node called `NumberLiteral` and setting its")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// value to the value of our token.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NumberLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If we have a string we will do the same as number and create a")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `StringLiteral` node.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'string'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      current"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'StringLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next we're going to look for CallExpressions. We start this off when we")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// encounter an open parenthesis.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'paren'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v("\n      token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'('")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll increment `current` to skip the parenthesis since we don't care")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// about it in our AST.")]),t._v("\n      token "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We create a base node with the type `CallExpression`, and we're going")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// to set the name as the current token's value since the next token after")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the open parenthesis is the name of the function.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CallExpression'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We increment `current` *again* to skip the name token.")]),t._v("\n      token "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And now we want to loop through each token that will be the `params` of")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// our `CallExpression` until we encounter a closing parenthesis.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Now this is where recursion comes in. Instead of trying to parse a")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// potentially infinitely nested set of nodes we're going to rely on")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// recursion to resolve things.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// To explain this, let's take our Lisp code. You can see that the")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// parameters of the `add` are a number and a nested `CallExpression` that")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// includes its own numbers.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   (add 2 (subtract 4 2))")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// You'll also notice that in our tokens array we have multiple closing")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// parenthesis.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   [")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'paren',  value: '('        },")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'name',   value: 'add'      },")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'number', value: '2'        },")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'paren',  value: '('        },")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'name',   value: 'subtract' },")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'number', value: '4'        },")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'number', value: '2'        },")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'paren',  value: ')'        }, <<< Closing parenthesis")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     { type: 'paren',  value: ')'        }, <<< Closing parenthesis")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   ]")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We're going to rely on the nested `walk` function to increment our")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `current` variable past any nested `CallExpression`.")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// So we create a `while` loop that will continue until it encounters a")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// token with a `type` of `'paren'` and a `value` of a closing")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// parenthesis.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'paren'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'paren'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("')'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// we'll call the `walk` function which will return a `node` and we'll")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// push it into our `node.params`.")]),t._v("\n        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("walk")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        token "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Finally we will increment `current` one last time to skip the closing")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// parenthesis.")]),t._v("\n      current"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And return the node.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Again, if we haven't recognized the token type by now we're going to")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// throw an error.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeError")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("token"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Now, we're going to create our AST which will have a root which is a")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `Program` node.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" ast "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Program'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And we're going to kickstart our `walk` function, pushing nodes to our")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `ast.body` array.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The reason we are doing this inside a loop is because our program can have")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `CallExpression` after one another instead of being nested.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   (add 2 2)")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   (subtract 4 2)")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    ast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("walk")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// At the end of our parser we'll return the AST.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" ast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * ============================================================================\n *                                 ⌒(❀>◞౪◟<❀)⌒\n *                               THE TRAVERSER!!!\n * ============================================================================\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * So now we have our AST, and we want to be able to visit different nodes with\n * a visitor. We need to be able to call the methods on the visitor whenever we\n * encounter a node with a matching type.\n *\n *   traverse(ast, {\n *     Program: {\n *       enter(node, parent) {\n *         // ...\n *       },\n *       exit(node, parent) {\n *         // ...\n *       },\n *     },\n *\n *     CallExpression: {\n *       enter(node, parent) {\n *         // ...\n *       },\n *       exit(node, parent) {\n *         // ...\n *       },\n *     },\n *\n *     NumberLiteral: {\n *       enter(node, parent) {\n *         // ...\n *       },\n *       exit(node, parent) {\n *         // ...\n *       },\n *     },\n *   });\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// So we define a traverser function which accepts an AST and a")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// visitor. Inside we're going to define two functions...")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverser")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("ast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" visitor")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// A `traverseArray` function that will allow us to iterate over an array and")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// call the next function that we will define: `traverseNode`.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverseArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("forEach")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("child")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverseNode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `traverseNode` will accept a `node` and its `parent` node. So that it can")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// pass both to our visitor methods.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverseNode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We start by testing for the existence of a method on the visitor with a")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// matching `type`.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" methods "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" visitor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If there is an `enter` method for this node type we'll call it with the")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `node` and its `parent`.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("methods "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" methods"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("enter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      methods"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("enter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next we are going to split things up by the current node type.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("switch")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll start with our top level `Program`. Since Program nodes have a")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// property named body that has an array of nodes, we will call")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `traverseArray` to traverse down into them.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// (Remember that `traverseArray` will in turn call `traverseNode` so  we")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// are causing the tree to be traversed recursively)")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Program'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverseArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next we do the same with `CallExpression` and traverse their `params`.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CallExpression'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverseArray")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("params"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// In the cases of `NumberLiteral` and `StringLiteral` we don't have any")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// child nodes to visit, so we'll just break.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NumberLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'StringLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And again, if we haven't recognized the node type then we'll throw an")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// error.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeError")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If there is an `exit` method for this node type we'll call it with the")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `node` and its `parent`.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("methods "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" methods"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      methods"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("exit")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Finally we kickstart the traverser by calling `traverseNode` with our ast")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// with no `parent` because the top level of the AST doesn't have a parent.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverseNode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * ============================================================================\n *                                   ⁽(◍˃̵͈̑ᴗ˂̵͈̑)⁽\n *                              THE TRANSFORMER!!!\n * ============================================================================\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * Next up, the transformer. Our transformer is going to take the AST that we\n * have built and pass it to our traverser function with a visitor and will\n * create a new ast.\n *\n * ----------------------------------------------------------------------------\n *   Original AST                     |   Transformed AST\n * ----------------------------------------------------------------------------\n *   {                                |   {\n *     type: 'Program',               |     type: 'Program',\n *     body: [{                       |     body: [{\n *       type: 'CallExpression',      |       type: 'ExpressionStatement',\n *       name: 'add',                 |       expression: {\n *       params: [{                   |         type: 'CallExpression',\n *         type: 'NumberLiteral',     |         callee: {\n *         value: '2'                 |           type: 'Identifier',\n *       }, {                         |           name: 'add'\n *         type: 'CallExpression',    |         },\n *         name: 'subtract',          |         arguments: [{\n *         params: [{                 |           type: 'NumberLiteral',\n *           type: 'NumberLiteral',   |           value: '2'\n *           value: '4'               |         }, {\n *         }, {                       |           type: 'CallExpression',\n *           type: 'NumberLiteral',   |           callee: {\n *           value: '2'               |             type: 'Identifier',\n *         }]                         |             name: 'subtract'\n *       }]                           |           },\n *     }]                             |           arguments: [{\n *   }                                |             type: 'NumberLiteral',\n *                                    |             value: '4'\n * ---------------------------------- |           }, {\n *                                    |             type: 'NumberLiteral',\n *                                    |             value: '2'\n *                                    |           }]\n *  (sorry the other one is longer.)  |         }\n *                                    |       }\n *                                    |     }]\n *                                    |   }\n * ----------------------------------------------------------------------------\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// So we have our transformer function which will accept the lisp ast.")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transformer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("ast")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll create a `newAst` which like our previous AST will have a program")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// node.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" newAst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Program'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next I'm going to cheat a little and create a bit of a hack. We're going to")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// use a property named `context` on our parent nodes that we're going to push")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// nodes to their parent's `context`. Normally you would have a better")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// abstraction than this, but for our purposes this keeps things simple.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Just take note that the context is a reference *from* the old ast *to* the")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// new ast.")]),t._v("\n  ast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_context "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newAst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll start by calling the traverser function with our ast and a visitor.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverser")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The first visitor method accepts any `NumberLiteral`")]),t._v("\n    NumberLiteral"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll visit them on enter.")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("enter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll create a new node also named `NumberLiteral` that we will push to")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the parent context.")]),t._v("\n        parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NumberLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next we have `StringLiteral`")]),t._v("\n    StringLiteral"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("enter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'StringLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next up, `CallExpression`.")]),t._v("\n    CallExpression"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("enter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" parent")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We start creating a new node `CallExpression` with a nested")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `Identifier`.")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" expression "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CallExpression'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          callee"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Identifier'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          arguments"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Next we're going to define a new context on the original")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `CallExpression` node that will reference the `expression`'s arguments")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// so that we can push arguments.")]),t._v("\n        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_context "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" expression"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arguments"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Then we're going to check if the parent node is a `CallExpression`.")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If it is not...")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CallExpression'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n          "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We're going to wrap our `CallExpression` node with an")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `ExpressionStatement`. We do this because the top level")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `CallExpression` in JavaScript are actually statements.")]),t._v("\n          expression "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ExpressionStatement'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            expression"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" expression"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Last, we push our (possibly wrapped) `CallExpression` to the `parent`'s")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// `context`.")]),t._v("\n        parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("expression"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// At the end of our transformer function we'll return the new ast that we")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// just created.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" newAst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * ============================================================================\n *                               ヾ（〃＾∇＾）ﾉ♪\n *                            THE CODE GENERATOR!!!!\n * ============================================================================\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * Now let's move onto our last phase: The Code Generator.\n *\n * Our code generator is going to recursively call itself to print each node in\n * the tree into one giant string.\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("codeGenerator")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("node")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We'll break things down by the `type` of the `node`.")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("switch")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If we have a `Program` node. We will map through each node in the `body`")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// and run them through the code generator and join them with a newline.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Program'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("codeGenerator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\n'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// For `ExpressionStatement` we'll call the code generator on the nested")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// expression and we'll add a semicolon...")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ExpressionStatement'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("codeGenerator")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expression"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("';'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// << (...because we like to code the *correct* way)")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// For `CallExpression` we will print the `callee`, add an open")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// parenthesis, we'll map through each node in the `arguments` array and run")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// them through the code generator, joining them with a comma, and then")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// we'll add a closing parenthesis.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CallExpression'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("codeGenerator")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("callee"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'('")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arguments"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("codeGenerator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("', '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("')'")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// For `Identifier` we'll just return the `node`'s name.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Identifier'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// For `NumberLiteral` we'll just return the `node`'s value.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NumberLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// For `StringLiteral` we'll add quotations around the `node`'s value.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'StringLiteral'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\"'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\"'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// And if we haven't recognized the node, we'll throw an error.")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TypeError")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * ============================================================================\n *                                  (۶* ‘ヮ’)۶”\n *                         !!!!!!!!THE COMPILER!!!!!!!!\n * ============================================================================\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * FINALLY! We'll create our `compiler` function. Here we will link together\n * every part of the pipeline.\n *\n *   1. input  => tokenizer   => tokens\n *   2. tokens => parser      => ast\n *   3. ast    => transformer => newAst\n *   4. newAst => generator   => output\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compiler")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" tokens "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("tokenizer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" ast    "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("parser")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tokens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" newAst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transformer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" output "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("codeGenerator")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newAst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// and simply return the output!")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * ============================================================================\n *                                   (๑˃̵ᴗ˂̵)و\n * !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!YOU MADE IT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n * ============================================================================\n */")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Now I'm just exporting everything...")]),t._v("\nmodule"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exports "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  tokenizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  traverser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  transformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  codeGenerator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  compiler"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])])},[],!1,null,null,null);s.default=e.exports}}]);